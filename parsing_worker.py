#!/usr/bin/env python3
"""
parsing_worker.py - –í–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑ Redis –æ—á–µ—Ä–µ–¥–∏
–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞—á–∏ –æ—Ç RationBot, –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
"""
import asyncio
import json
import logging
import sys
import time
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(str(Path(__file__).parent))

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
from address import VkusvillFastParser, AntiBotClient, get_location_from_address

# Redis –∫–ª–∏–µ–Ω—Ç
import redis.asyncio as aioredis

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ParsingWorker:
    """–í–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Redis."""

    def __init__(self, redis_url: str):
        self.redis_url = redis_url
        self.redis = None
        self.parsing_queue = "parsing_queue"
        self.results_queue_prefix = "results:"
        self.antibot_client = None
        self.parser = None
        self.base_csv_path = Path("data/moscow_improved_1758362624.csv")
        self.base_df = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "tasks_processed": 0,
            "tasks_success": 0,
            "tasks_error": 0,
            "total_time": 0,
            "start_time": datetime.now().isoformat()
        }

    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞."""
        try:
            self.redis = await aioredis.from_url(
                self.redis_url,
                encoding="utf-8",
                decode_responses=True
            )
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Redis")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
            self.antibot_client = AntiBotClient(concurrency=10, timeout=30)
            self.parser = VkusvillFastParser(self.antibot_client)

            # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
            if self.base_csv_path.exists():
                logger.info(f"üìö –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã: {self.base_csv_path}")
                self.base_df = pd.read_csv(self.base_csv_path)
                logger.info(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.base_df)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
                self.parser.heavy_data = {}
                for _, row in self.base_df.iterrows():
                    self.parser.heavy_data[row['id']] = row.to_dict()
            else:
                logger.warning(f"‚ö†Ô∏è –ë–∞–∑–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.base_csv_path}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            raise

    async def disconnect(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç Redis."""
        if self.redis:
            await self.redis.close()
        if self.antibot_client:
            await self.antibot_client.close()

    async def send_heartbeat(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ heartbeat –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        while True:
            try:
                await self.redis.set(
                    "parser:heartbeat",
                    datetime.now().isoformat(),
                    ex=60  # TTL 60 —Å–µ–∫—É–Ω–¥
                )

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                avg_time = (self.stats["total_time"] / self.stats["tasks_processed"]
                            if self.stats["tasks_processed"] > 0 else 0)

                stats_data = {
                    **self.stats,
                    "avg_time": avg_time,
                    "uptime": (datetime.now() - datetime.fromisoformat(self.stats["start_time"])).total_seconds()
                }

                await self.redis.set(
                    "parser:stats",
                    json.dumps(stats_data),
                    ex=3600  # TTL 1 —á–∞—Å
                )

                await asyncio.sleep(30)  # Heartbeat –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ heartbeat: {e}")
                await asyncio.sleep(30)

    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞."""
        task_id = task.get("task_id")
        user_id = task.get("user_id")
        mode = task.get("mode", "fast")

        logger.info(f"üì• –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ {task_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")

        start_time = time.time()

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–º–µ–Ω–µ–Ω–∞ –ª–∏ –∑–∞–¥–∞—á–∞
            cancelled = await self.redis.sismember("cancelled_tasks", task_id)
            if cancelled:
                logger.info(f"üö´ –ó–∞–¥–∞—á–∞ {task_id} –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                return None

            if mode == "full":
                # –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                result_df = await self.run_full_parsing()
            else:
                # –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏
                result_df = await self.run_fast_parsing(task)

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                "status": "success",
                "data": result_df.to_dict('records') if result_df is not None else [],
                "error_message": None
            }

            self.stats["tasks_success"] += 1
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ {task_id}: {e}")

            result = {
                "status": "error",
                "data": None,
                "error_message": str(e)
            }

            self.stats["tasks_error"] += 1

        finally:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats["tasks_processed"] += 1
            self.stats["total_time"] += time.time() - start_time

        return result

    async def run_fast_parsing(self, task: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏."""
        coordinates = task.get("coordinates", {})
        lat = coordinates.get("lat", 55.7558)
        lon = coordinates.get("lon", 37.6176)
        address = task.get("address", f"{lat},{lon}")

        logger.info(f"üó∫Ô∏è –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è: {address}")

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            city = "–ú–æ—Å–∫–≤–∞"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            coords = f"{lat},{lon}"

            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ (–ø–æ–ª—É—á–∞–µ–º ID –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤)
            products = await self.parser.scrape_fast(
                city=city,
                coords=coords,
                address=address,
                limit=1500  # –ú–∞–∫—Å–∏–º—É–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤
            )

            if products:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
                df = pd.DataFrame(products)
                logger.info(f"   –ù–∞–π–¥–µ–Ω–æ {len(df)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
                return df
            else:
                logger.warning("   –ü—Ä–æ–¥—É–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –Ω–∞–±–æ—Ä –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                if self.base_df is not None:
                    return self.base_df.head(100)
                return pd.DataFrame()

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
            if self.base_df is not None:
                return self.base_df.head(100)
            raise

    async def run_full_parsing(self) -> Optional[pd.DataFrame]:
        """–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤."""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞...")

        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
            from moscow_improved import VkusvillHeavyParser

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            heavy_parser = VkusvillHeavyParser(self.antibot_client)

            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
            products = await heavy_parser.scrape_heavy(limit=1500)

            if products:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                df = pd.DataFrame(products)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
                timestamp = int(time.time())
                new_csv_path = Path(f"data/moscow_improved_{timestamp}.csv")
                new_csv_path.parent.mkdir(exist_ok=True)

                df.to_csv(new_csv_path, index=False, encoding='utf-8')
                logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {new_csv_path}")

                # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
                self.base_df = df
                self.base_csv_path = new_csv_path

                # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –ø–∞—Ä—Å–µ—Ä–∞
                self.parser.heavy_data = {}
                for _, row in df.iterrows():
                    self.parser.heavy_data[row['id']] = row.to_dict()

                return df
            else:
                logger.warning("–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                return self.base_df

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            raise

    async def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á."""
        logger.info("üöÄ –í–æ—Ä–∫–µ—Ä –ø–∞—Ä—Å–µ—Ä–∞ –∑–∞–ø—É—â–µ–Ω")

        # –ó–∞–ø—É—Å–∫–∞–µ–º heartbeat –≤ —Ñ–æ–Ω–µ
        asyncio.create_task(self.send_heartbeat())

        while True:
            try:
                # –ë–ª–æ–∫–∏—Ä—É—é—â–µ–µ —á—Ç–µ–Ω–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                result = await self.redis.brpop(self.parsing_queue, timeout=5)

                if result:
                    _, task_json = result
                    task = json.loads(task_json)

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–¥–∞—á—É
                    result = await self.process_task(task)

                    if result:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        task_id = task.get("task_id")
                        result_key = f"{self.results_queue_prefix}{task_id}"

                        await self.redis.set(
                            result_key,
                            json.dumps(result),
                            ex=300  # TTL 5 –º–∏–Ω—É—Ç
                        )

                        logger.info(f"üì§ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {result_key}")

            except asyncio.TimeoutError:
                # –¢–∞–π–º–∞—É—Ç - –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                continue

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                await asyncio.sleep(5)


async def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤–æ—Ä–∫–µ—Ä–∞."""
    import os
    from dotenv import load_dotenv

    load_dotenv()

    # –ü–æ–ª—É—á–∞–µ–º URL Redis –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    redis_url = os.getenv("REDIS_PUBLIC_URL", "redis://localhost:6379")

    logger.info("=" * 50)
    logger.info("üöÄ VKUSVILL PARSER WORKER")
    logger.info(f"üìç Redis: {redis_url}")
    logger.info("=" * 50)

    worker = ParsingWorker(redis_url)

    try:
        await worker.connect()
        await worker.run()
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞...")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        await worker.disconnect()


if __name__ == "__main__":
    asyncio.run(main())